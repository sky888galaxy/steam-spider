#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import sys
import time
import csv
from pathlib import Path

BASE_DIR = Path(__file__).parent.parent
DATA_DIR = BASE_DIR / "data"
sys.path.insert(0, str(BASE_DIR / "src"))

from steam_data_extractor import (
    fetch_search_page,
    parse_search_html,
    get_price_from_api,
    get_tags_from_app_page,
    merge_tags,
    price_fallback_from_text,
    save_csv
)
from clean.data_cleaner import clean_data
from comments.simple_steam_crawler_easy import analyze_game_threats


class SteamAnalysisPipeline:

    def __init__(self):
        self.raw_csv = DATA_DIR / "steam_topsellers_simple.csv"
        self.cleaned_csv = DATA_DIR / "steam_topsellers_simple_cleaned.csv"
        self.comment_analysis_csv = DATA_DIR / "comment_analysis_results.csv"
        self.suspicious_reviews_csv = DATA_DIR / "suspicious_reviews_details.csv"
        self.games_data = []

    def step1_extract_games(self, pages=1):
        print("\n" + "=" * 60)
        print("ã€æ­¥éª¤ 1/4ã€‘æŠ“å–Steamæ¸¸æˆæ•°æ®")
        print("=" * 60)
        all_items = []
        for p in range(1, pages + 1):
            print(f"æŠ“å–æœç´¢é¡µ page {p} ...")
            html = fetch_search_page(page=p, filter_name="topsellers")
            items = parse_search_html(html)
            all_items.extend(items)
            time.sleep(1.0)
        out = []
        for i, it in enumerate(all_items, 1):
            appid = it.get("appid", "")
            title = it.get("title", "")
            print(f"[{i}/{len(all_items)}] {title[:50]}  (appid={appid})")
            record = {
                "appid": appid,
                "title": title,
                "released": it.get("released", ""),
                "current_price": "",
                "original_price": "",
                "tags": "",
                "release_date": it.get("released", ""),
                "review_score": "",
                "developer": ""
            }
            if appid:
                price_info = get_price_from_api(appid, cc="US", lang="en")
                if price_info and price_info.get("final") is not None:
                    record["current_price"] = str(price_info.get("final"))
                    record["original_price"] = str(price_info.get("initial")) if price_info.get("initial") is not None else ""
                else:
                    cur, orig = price_fallback_from_text(it.get("price_text", ""))
                    record["current_price"] = cur
                    record["original_price"] = orig
                tags_page = get_tags_from_app_page(appid)
                merged = merge_tags(it.get("tags_text", ""), tags_page)
                record["tags"] = merged
            else:
                cur, orig = price_fallback_from_text(it.get("price_text", ""))
                record["current_price"] = cur
                record["original_price"] = orig
                record["tags"] = it.get("tags_text", "")
            out.append(record)
            time.sleep(1.0)
        save_csv(out, str(self.raw_csv))
        self.games_data = out
        print(f"\nâœ“ å®Œæˆï¼šä¿å­˜ {len(out)} æ¡æ¸¸æˆæ•°æ®åˆ° {self.raw_csv.name}")
        return out

    def step2_clean_data(self):
        print("\n" + "=" * 60)
        print("ã€æ­¥éª¤ 2/4ã€‘æ¸…æ´—æ•°æ®")
        print("=" * 60)
        import clean.data_cleaner as cleaner
        original_input = getattr(cleaner, "INPUT_FILE", None)
        original_output = getattr(cleaner, "OUTPUT_FILE", None)
        cleaner.INPUT_FILE = str(self.raw_csv)
        cleaner.OUTPUT_FILE = str(self.cleaned_csv)
        try:
            clean_data()
            print(f"\nâœ“ å®Œæˆï¼šæ¸…æ´—åæ•°æ®ä¿å­˜åˆ° {self.cleaned_csv.name}")
        finally:
            if original_input is not None:
                cleaner.INPUT_FILE = original_input
            if original_output is not None:
                cleaner.OUTPUT_FILE = original_output

    def step3_analyze_comments(self, max_games=5, max_reviews_per_game=20):
        print("\n" + "=" * 60)
        print(f"ã€æ­¥éª¤ 3/4ã€‘åˆ†ææ¸¸æˆè¯„è®ºå¨èƒï¼ˆå‰{max_games}æ¬¾æ¸¸æˆï¼‰")
        print("=" * 60)
        try:
            with open(self.cleaned_csv, 'r', encoding='utf-8-sig') as f:
                games = list(csv.DictReader(f))[:max_games]
        except FileNotFoundError:
            print(f"é”™è¯¯ï¼šæ‰¾ä¸åˆ°æ¸…æ´—åçš„æ–‡ä»¶ {self.cleaned_csv}")
            return []
        results = []
        for i, game in enumerate(games, 1):
            app_id = game.get('appid', '').strip()
            title = game.get('title', '').strip()
            if not app_id or not title:
                continue
            print(f"\n[{i}/{len(games)}] æ­£åœ¨åˆ†æ: {title}")
            result = analyze_game_threats(app_id, title, max_reviews_per_game)
            if result:
                results.append(result)
                print(f"  âœ“ å®Œæˆ: åˆ†æ{result['total_reviews']}æ¡è¯„è®º, "
                      f"å‘ç°{result['suspicious_reviews']}æ¡å¯ç–‘ "
                      f"({result['threat_rate'] * 100:.1f}%)")
            else:
                print(f"  âœ— æ— æ³•è·å–è¯„è®º")
            time.sleep(2)
        if results:
            with open(self.comment_analysis_csv, 'w', newline='', encoding='utf-8-sig') as f:
                fieldnames = ['appid', 'title', 'total_reviews', 'suspicious_reviews',
                              'threat_rate', 'links', 'keywords', 'contacts', 'avg_helpful',
                              'chinese_reviews', 'english_reviews']
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                writer.writeheader()
                for r in results:
                    writer.writerow({
                        'appid': r['appid'],
                        'title': r['title'],
                        'total_reviews': r['total_reviews'],
                        'suspicious_reviews': r['suspicious_reviews'],
                        'threat_rate': f"{r['threat_rate'] * 100:.2f}%",
                        'links': r['threat_stats']['links'],
                        'keywords': r['threat_stats']['keywords'],
                        'contacts': r['threat_stats']['contacts'],
                        'avg_helpful': f"{r.get('avg_helpful', 0):.1f}",
                        'chinese_reviews': r.get('language_stats', {}).get('chinese', 0),
                        'english_reviews': r.get('language_stats', {}).get('english', 0)
                    })
            print(f"\nâœ“ å®Œæˆï¼šè¯„è®ºåˆ†æç»“æœä¿å­˜åˆ° {self.comment_analysis_csv.name}")
            suspicious_details = []
            for r in results:
                if 'details' in r and r['details']:
                    for detail in r['details']:
                        suspicious_details.append({
                            'appid': r['appid'],
                            'game_title': r['title'],
                            'review_index': detail['index'],
                            'review_content': detail['content'],
                            'page': detail['page'],
                            'helpful': detail['helpful'],
                            'language': detail['language'],
                            'has_links': 'æ˜¯' if detail['threats']['links'] > 0 else 'å¦',
                            'has_keywords': 'æ˜¯' if detail['threats']['keywords'] > 0 else 'å¦',
                            'has_contacts': 'æ˜¯' if detail['threats']['contacts'] > 0 else 'å¦',
                            'link_count': detail['threats']['links'],
                            'keyword_count': detail['threats']['keywords'],
                            'contact_count': detail['threats']['contacts']
                        })
            if suspicious_details:
                with open(self.suspicious_reviews_csv, 'w', newline='', encoding='utf-8-sig') as f:
                    fieldnames = ['appid', 'game_title', 'review_index', 'review_content', 'page',
                                  'helpful', 'language', 'has_links', 'has_keywords', 'has_contacts',
                                  'link_count', 'keyword_count', 'contact_count']
                    writer = csv.DictWriter(f, fieldnames=fieldnames)
                    writer.writeheader()
                    writer.writerows(suspicious_details)
                print(f"âœ“ å®Œæˆï¼šå¯ç–‘è¯„è®ºè¯¦æƒ…ä¿å­˜åˆ° {self.suspicious_reviews_csv.name}")
                print(f"  å…±è®°å½• {len(suspicious_details)} æ¡å¯ç–‘è¯„è®º")
        return results

    def step4_visualize_analysis(self, show_plots=True):
        print("\n" + "=" * 60)
        print("ã€æ­¥éª¤ 4/4ã€‘æ•°æ®åˆ†æä¸å¯è§†åŒ–")
        print("=" * 60)
        if not show_plots:
            print(f"âœ“ å®Œæˆï¼šè·³è¿‡å›¾è¡¨æ˜¾ç¤º")
            return
        analysis_dir = BASE_DIR / "src" / "analysis part"
        if str(analysis_dir) not in sys.path:
            sys.path.insert(0, str(analysis_dir))
        try:
            from data_analysis import run_analysis
            run_analysis(str(self.cleaned_csv))
            print(f"\nâœ“ å®Œæˆï¼šæ•°æ®åˆ†æä¸å¯è§†åŒ–")
        except Exception as e:
            print(f"âš  å¯è§†åŒ–å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()

    def run_full_pipeline(self, pages=3, max_comment_games=15, max_reviews=50, show_plots=True):
        print("\n" + "=" * 70)
        print("ğŸ® æˆ‘è¶…æƒ³ä½ steam spider ğŸ•·ï¸")
        print("=" * 70)
        print(f"é…ç½®:")
        print(f"  - æŠ“å–é¡µæ•°: {pages}")
        print(f"  - è¯„è®ºåˆ†ææ¸¸æˆæ•°: {max_comment_games}")
        print(f"  - æ¯æ¬¾æ¸¸æˆè¯„è®ºæ•°: {max_reviews}")
        print(f"  - æ˜¾ç¤ºå›¾è¡¨: {'æ˜¯' if show_plots else 'å¦'}")
        print("=" * 70)
        start_time = time.time()
        try:
            games = self.step1_extract_games(pages=pages)
            self.step2_clean_data()
            comment_results = self.step3_analyze_comments(
                max_games=max_comment_games,
                max_reviews_per_game=max_reviews
            )
            self.step4_visualize_analysis(show_plots=show_plots)
            elapsed = time.time() - start_time
            print("\n" + "=" * 70)
            print("æµæ°´çº¿æ‰§è¡Œå®Œæˆï¼")
            print("=" * 70)
            print(f"æ€»è€—æ—¶: {elapsed:.1f}ç§’")
            print(f"æ¸¸æˆæ•°æ®: {len(games)} æ¡")
            print(f"è¯„è®ºåˆ†æ: {len(comment_results)} æ¬¾æ¸¸æˆ")
            print(f"\nç”Ÿæˆæ–‡ä»¶:")
            print(f"  - {self.raw_csv}")
            print(f"  - {self.cleaned_csv}")
            print(f"  - {self.comment_analysis_csv}")
            if self.suspicious_reviews_csv.exists():
                print(f"  - {self.suspicious_reviews_csv}")
            print("=" * 70)
            print("\nğŸ‰ æˆ‘è¶…æƒ³ä½ steam spider è¿è¡Œå®Œæˆï¼ğŸ‰")
            print("=" * 70)
            return True
        except KeyboardInterrupt:
            print("\n\nç”¨æˆ·ä¸­æ–­æ‰§è¡Œ")
            return False
        except Exception as e:
            print(f"\n\né”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return False


def main():
    import argparse
    parser = argparse.ArgumentParser(description='Steamæ•°æ®åˆ†ææµæ°´çº¿')
    parser.add_argument('--pages', type=int, default=3, help='æŠ“å–é¡µæ•° (é»˜è®¤3)')
    parser.add_argument('--games', type=int, default=15, help='è¯„è®ºåˆ†ææ¸¸æˆæ•° (é»˜è®¤15)')
    parser.add_argument('--reviews', type=int, default=50, help='æ¯æ¬¾æ¸¸æˆè¯„è®ºæ•° (é»˜è®¤50)')
    parser.add_argument('--no-plots', action='store_true', help='ä¸æ˜¾ç¤ºå›¾è¡¨')
    parser.add_argument('--step', type=str, choices=['1', '2', '3', '4', 'all'],
                        default='all', help='æ‰§è¡Œç‰¹å®šæ­¥éª¤ (1-4) æˆ–å…¨éƒ¨ (all)')
    args = parser.parse_args()
    pipeline = SteamAnalysisPipeline()
    if args.step == 'all':
        pipeline.run_full_pipeline(
            pages=args.pages,
            max_comment_games=args.games,
            max_reviews=args.reviews,
            show_plots=not args.no_plots
        )
    elif args.step == '1':
        pipeline.step1_extract_games(args.pages)
    elif args.step == '2':
        pipeline.step2_clean_data()
    elif args.step == '3':
        pipeline.step3_analyze_comments(args.games, args.reviews)
    elif args.step == '4':
        pipeline.step4_visualize_analysis(not args.no_plots)


if __name__ == "__main__":
    main()
